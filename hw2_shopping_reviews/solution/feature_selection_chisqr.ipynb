{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7543cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import sklearn\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9bf67b",
   "metadata": {},
   "source": [
    "# Load training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd6de1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                             review\n",
      "0          0  Leaks: Liss seems to be totally incompetent: m...\n",
      "1          1  Replacement Peeler: Loved my old one. Loaned i...\n",
      "2          0  Not what I was expecting: I chose to rate this...\n",
      "3          1  Watch face is hard to read: Although I don't o...\n",
      "4          0  Disappointing: I was eager to read this book s...\n",
      "...      ...                                                ...\n",
      "29991      1  Love EW: I must admit that I am a total TV afi...\n",
      "29992      1  Easy to follow and delicious recipes!: I compl...\n",
      "29993      1  The Beauty and Mystery of Veronique: Perhaps t...\n",
      "29994      1  I love it.: Brilliant, hilarious, quick and ea...\n",
      "29995      0  broken...: bad choice...2d film would not play...\n",
      "\n",
      "[29996 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv('./train.tsv', sep = '\\t')\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c765ec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size: 23997\n",
      "validation set size: 5999\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8 # 80% for training, 20% for validation\n",
    "random_seed = 100\n",
    "\n",
    "train_dataframe = dataframe.sample(frac=train_ratio, random_state=random_seed)\n",
    "valid_dataframe = dataframe.drop(train_dataframe.index)\n",
    "print('training set size:', len(train_dataframe))\n",
    "print('validation set size:', len(valid_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "464fceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                             review\n",
      "0        1  Human Hurricane!: Would you like to sleep in t...\n",
      "1        2  A Mom: I bought this with all kinds of expecta...\n",
      "2        3  Good Read: I judge all books that I read by a ...\n",
      "3        4  It's awesome: DVD set is exactly what you'd bu...\n",
      "4        5  Great Movie!!!: This definatly the best Godzil...\n",
      "...    ...                                                ...\n",
      "5995  5996  Beautiful and Spiritual: This is a very beauti...\n",
      "5996  5997  Another Cash In: This cd is pure dreck and it'...\n",
      "5997  5998  Concept drawings-very good: The concept drawin...\n",
      "5998  5999  I hear i all the time is awsome: this is great...\n",
      "5999  6000  Not so great Performance: This mouse is very s...\n",
      "\n",
      "[6000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_dataframe = pd.read_csv('./test.tsv', sep = '\\t')\n",
    "print (test_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e47b1c",
   "metadata": {},
   "source": [
    "# Feature selection method: the chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c24c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_text(text):\n",
    "    for punctuations in [',', '.', '\"', '!', '?', ':', ';', '-', '(', ')', '[', ']']:\n",
    "        text = text.replace(punctuations, ' ')\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.lower().strip()\n",
    "    return text\n",
    "\n",
    "def get_single_word_frequency(filepath):\n",
    "    word_freq = {}\n",
    "    with open(filepath) as f:\n",
    "        f.readline() # skip header (the first line) \n",
    "        for line in f:\n",
    "            review_text = process_text(line.split('\\t')[1])\n",
    "            for word in review_text.split():\n",
    "                if word not in word_freq:\n",
    "                    word_freq[word] = 1\n",
    "                else:\n",
    "                    word_freq[word] += 1\n",
    "    return word_freq\n",
    "\n",
    "def get_single_word_doc_frequency_per_label(filepath, label):\n",
    "    word_freq_per_label = {}\n",
    "    with open(filepath) as f:\n",
    "        f.readline() # skip header (the first line) \n",
    "        for line in f:\n",
    "            sentiment_label = line.split('\\t')[0].strip()\n",
    "            if sentiment_label == label:\n",
    "                review_text = process_text(line.split('\\t')[1])\n",
    "                for word in set(review_text.split()):\n",
    "                    if word not in word_freq_per_label:\n",
    "                        word_freq_per_label[word] = 1\n",
    "                    else:\n",
    "                        word_freq_per_label[word] += 1\n",
    "    return word_freq_per_label\n",
    "\n",
    "def feature_selection_chi2(review_filepath, num_features_to_select):\n",
    "    num_reviews = 0\n",
    "    num_positive_reviews = 0\n",
    "    num_negative_reviews = 0\n",
    "    with open(review_filepath) as f:\n",
    "        f.readline() # skip header (the first line) \n",
    "        for line in f:\n",
    "            num_reviews += 1\n",
    "            if line.strip().split()[0] == '1':\n",
    "                num_positive_reviews += 1\n",
    "            else:\n",
    "                num_negative_reviews += 1\n",
    "    word_freq = get_single_word_frequency(review_filepath)\n",
    "    positive_word_freq = get_single_word_doc_frequency_per_label(review_filepath, '1')\n",
    "    negative_word_freq = get_single_word_doc_frequency_per_label(review_filepath, '0')\n",
    "    \n",
    "    chi2_dict = {}\n",
    "    for word, freq in word_freq.items():\n",
    "        if word in positive_word_freq and word in negative_word_freq:        \n",
    "            contingency_table = np.zeros((2,2))\n",
    "            contingency_table[0][0] = positive_word_freq[word]\n",
    "            contingency_table[0][1] = negative_word_freq[word]\n",
    "            contingency_table[1][0] = num_positive_reviews - positive_word_freq[word]\n",
    "            contingency_table[1][1] = num_negative_reviews - negative_word_freq[word]\n",
    "\n",
    "            chi2 = 0.0\n",
    "            for i in range(2):\n",
    "                for j in range(2):\n",
    "                    expected_count = sum(contingency_table[i,:])*sum(contingency_table[:,j])/float(num_reviews)\n",
    "                    chi2 += (contingency_table[i][j] - expected_count)**2 / expected_count\n",
    "\n",
    "            chi2_dict[word] = chi2\n",
    "    feature_set = set([])\n",
    "    for word, chi2 in sorted(chi2_dict.items(), key = lambda x: x[1], reverse = True)[:num_features_to_select]:\n",
    "        feature_set.add(word)\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe1bcc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(vocabulary={'#', '#1', '#10', '#15', '#2', '#4', '#5', '#6',\n",
       "                            '#7', '#8', '#9', '$', '$$', '$$$', '$0', '$1',\n",
       "                            '$10', '$100', '$11', '$12', '$13', '$14', '$15',\n",
       "                            '$150', '$18', '$19', '$2', '$20', '$200', '$22', ...})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = 15000\n",
    "feature_set = feature_selection_chi2('./train.tsv', num_features)\n",
    "vectorizer = CountVectorizer(vocabulary = feature_set)\n",
    "vectorizer.fit(train_dataframe['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213bd794",
   "metadata": {},
   "source": [
    "# Extract feature vectors for training, validation, and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de19521d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23997, 15000)\n",
      "(5999, 15000)\n",
      "(6000, 15000)\n"
     ]
    }
   ],
   "source": [
    "train_X = vectorizer.transform(train_dataframe['review'])\n",
    "valid_X = vectorizer.transform(valid_dataframe['review'])\n",
    "test_X = vectorizer.transform(test_dataframe['review'])\n",
    "print (train_X.shape)\n",
    "print (valid_X.shape)\n",
    "print (test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "527ca7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, solver='liblinear')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y = train_dataframe['label']\n",
    "model = LogisticRegression(C = 0.1, solver='liblinear')\n",
    "model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf46ab6c",
   "metadata": {},
   "source": [
    "# Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86ecf08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, solver='liblinear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model on training set\n",
    "train_Y = train_dataframe['label']\n",
    "model = LogisticRegression(C = 0.1, solver='liblinear')\n",
    "model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee84685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression, accuracy on training set: 0.9343667958494812\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on training set\n",
    "train_Y_hat = model.predict(train_X)\n",
    "train_Y = train_dataframe['label'].to_numpy()\n",
    "accuracy = accuracy_score(train_Y, train_Y_hat)\n",
    "print ('Logistic regression, accuracy on training set:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa3775b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression, accuracy on validation set: 0.8826471078513085\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on validation set\n",
    "valid_Y_hat = model.predict(valid_X)\n",
    "valid_Y = valid_dataframe['label'].to_numpy()\n",
    "accuracy = accuracy_score(valid_Y, valid_Y_hat)\n",
    "print ('Logistic regression, accuracy on validation set:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6fff5b",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "898ca56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: write out prediction values into a csv format file\n",
    "# params:\n",
    "#     df: dataframe, where each row is a test example, with column 'id' as data id\n",
    "#     pred: a list or 1-d array of prediction values\n",
    "#     filepath: the output file path\n",
    "# return:\n",
    "#     None\n",
    "\n",
    "def write_test_prediction(df, pred, filepath):\n",
    "    with open(filepath, 'w') as outfile:\n",
    "        outfile.write('{},{}\\n'.format('id', 'label'))\n",
    "        for index, row in df.iterrows():\n",
    "            outfile.write('{},{}\\n'.format(row['id'], pred[index]))\n",
    "    print (len(df), 'predictions are written to', filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aa2039f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 predictions are written to ./logistic_regression_chisqr.csv\n"
     ]
    }
   ],
   "source": [
    "# After experimentation on the validation set: retrain the final model on all training data, and predict labels for test data\n",
    "all_train_Y = dataframe['label']\n",
    "all_train_X = vectorizer.transform(dataframe['review'])\n",
    "model.fit(all_train_X, all_train_Y)\n",
    "test_Y_hat = model.predict(test_X)\n",
    "write_test_prediction(test_dataframe, test_Y_hat, './logistic_regression_chisqr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9975462e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
